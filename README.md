# **Victor Araujo Paula Cavichioli**

### **Tabela de conteúdos**

- [Introdução](#introdução)
- [Meus Principais Conhecimentos](#meus-principais-conhecimentos)
- [Projeto 1 - Fatec](#projeto-1)
    - [Parceiro Acadêmico](#parceiro-p1)
    - [Objetivo do Projeto](#objetivo-p1)
    - [Tecnologias Utilizadas](#tecnologias-p1)
    - [Ferramentas Utilizadas](#ferranentas-p1)
    - [Contribuições Pessoais](#contribuições-p1)
        - [Funções que Reconhecem Voz e Transformam em Texto](#funções-voz-p1)
        - [Requisição e Interpretação de Dados Vindos da Web](#requisições-p1)
        - [Tratamento de Erros](#tratamento-p1)
    - [Aprendizados Efetivos](#aprendizados-p1)
- [Projeto 2 - Necto Systems](#projeto-2)
    - [Parceiro Acadêmico](#parceiro-p2)
    - [Objetivo do Projeto](#objetivo-p2)
    - [Tecnologias Utilizadas](#tecnologias-p2)
    - [Ferramentas Utilizadas](#ferramentas-p2)
    - [Contribuições Pessoais](#contribuições-p2)
        - [Tratamento de Erros](#tratamento-p2)
        - [Leitura de Dados Passados pelo Usuário](#leitura-p2)
        - [Métrica de Tamanho de Banco de Dados](#metrica-p2)
    - [Aprendizados Efetivos](#aprendizados-p2)
- [Projeto 3 - MidAll](#projeto-3)
    - [Parceiro Acadêmico](#parceiro-p3)
    - [Objetivo do Projeto](#objetivo-p3)
    - [Tecnologias Utilizadas](#tecnologias-p3)
    - [Ferramentas Utilizadas](#ferramentas-p3)
    - [Contribuições Pessoais](#contribuições-p3)
        - [Exposição dos Endpoints das Tabelas e Camada de Serviço](#exposição-p3)
        - [Modelo Básico de Dados](#modelo-p3)
        - [Módulo de Configurações da Aplicação](#configuração-p3)
        - [Integração do Front-end e Back-end Utilizando Typescript](#integração-p3)
	    - [Desenvolvimento de Telas Responsivas](#desenvolvimento-p3)
    - [Aprendizados Efetivos](#aprendizados-p3)
- [Projeto 4 - Subter](#projeto-4)
    - [Parceiro Acadêmico](#parceiro-p4)
    - [Objetivo do Projeto](#objetivo-p4)
    - [Tecnologias Utilizadas](#tecnologias-p4)
    - [Ferramentas Utilizadas](#ferramentas-p4)
    - [Contribuições Pessoais](#contribuições-p4)
        - [Exposição dos Endpoints das Tabelas e Camada de Serviço](#exposição-p4)
        - [Modelo Básico de Dados](#modelo-p4)
        - [Módulo de Configurações da Aplicação](#configuração-p4)
        - [Security](#security-p4)
        - [JsonView](#jsonview-p4)
        - [Dockerfile](#docker-p4)
    - [Aprendizados Efetivos](#aprendizados-p4)
- [Projeto 5 - MidAll](#projeto-5)
    - [Parceiro Acadêmico](#parceiro-p5)
    - [Objetivo do Projeto](#objetivo-p5)
    - [Tecnologias Utilizadas](#tecnologias-p5)
    - [Ferramentas Utilizadas](#ferramentas-p5)
    - [Contribuições Pessoais](#contribuições-p5)
	- [Google Drive API](#google-p5)
		- [Download](#download-p5)
		- [Upload](#upload-p5)
		- [Listar Arquivos](#list-p5)
		- [Padronização de Retornos](#padronização-p5)
		- [Config Errors](#config-p5)
	- [Continuous Integration](#ci-p5)
		- [Testes de Software](#ts-p5)
	- [Continuous Delivery](#cd-p5)
		- [K3D Cluster](#k3d-p5)
		- [AKS Cluster](#aks-p5)
		- [Kubernetes Deployment](#deployment-p5)
		- [Kubernetes StatefulSet](#statefulset-p5)
		- [Kubernetes Service ClusterIP](#service-ip-p5)
		- [Kubernetes Service LoadBalancer](#service-lb-p5)
		- [Kubernetes HorizontalPodAutoscaler](#hpa-p5)
		- [Kubernetes Ingress](#ingress-p5)
    - [Aprendizados Efetivos](#aprendizados-p4)
    - [Demonstração das Funcionalidades](#demo-p5)
- [Conclusões](#conclusões)
- [Referências](#referências)

### **Introdução**

Olá, seja bem-vindo. Me chamo Victor Cavichioli, sou estudante de **Banco de Dados** pela [FATEC Prof. Jessen Vidal](https://fatecsjc-prd.azurewebsites.net/). Tenho 19 anos e trabalho com DevOps e [Apache Cassandra](https://cassandra.apache.org/_/index.html). 

<img src="https://avatars.githubusercontent.com/u/79488234?v=4"/>

<h4><details id="meus-principais-conhecimentos" open>
<summary>Meus principais conhecimentos</summary>

<div style="display: inline_block"><br>
  <img align="center" alt="THL-Js" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/javascript/javascript-plain.svg">
  <img align="center" alt="THL-J" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/00f02ef57fb7601fd1ddcc2fe6fe670fef3ae3e4/icons/java/java-original.svg">
  <img align="center" alt="THL-Python" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg">
  <img align="center" alt="THL-Node" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/00f02ef57fb7601fd1ddcc2fe6fe670fef3ae3e4/icons/nodejs/nodejs-plain.svg">
  <img align="center" alt="THL-Docker" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-plain.svg">
  <img align="center" alt="THL-Kubernetes" height="30" width="40" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/kubernetes/kubernetes-plain.svg">
</div>

### **Python**

Python foi a primeira linguagem estudada no primeiro semestre da graduação. Atualmente, como DevOps, as principais atribuições são realizadas utilizando Python, também pela Fatec. Um projeto anterior envolveu o desenvolvimento de um assistente virtual em Python. No trabalho, Python é utilizado para integrar outros serviços, realizar operações de verificação no cluster e no **banco de dados**.

### **Java**
Java foi a terceira linguagem de programação aprendida. Antes de trabalhar com Python, houve um envolvimento prévio na área de faturamento, onde muitos dos serviços foram desenvolvidos em Java utilizando Spring Boot. Além disso, os projetos de API na Fatec também foram desenvolvidos em Java. Essa experiência agrega muito valor quando se trata de Java, especialmente no contexto de REST APIs.

### **Docker**
Docker é uma plataforma de virtualização de aplicativos que permite criar, empacotar e executar aplicativos em um ambiente isolado, conhecido como contêiner. Isso ajuda a garantir que os aplicativos sejam executados da mesma maneira em diferentes sistemas operacionais e ambientes, o que simplifica o processo de implantação e reduz os problemas de compatibilidade. Além disso, o Docker permite que vários contêineres compartilhem recursos de hardware, como CPU e memória, sem interferir uns nos outros. Essa capacidade de isolamento e compartilhamento de recursos é crucial para a construção de aplicativos escaláveis, confiáveis e eficientes [\[1\]](#referências). 

### **Kubernetes**
Kubernetes é uma plataforma de orquestração de contêineres que automatiza a implantação, a escala e a gestão de aplicativos em contêineres. Ele permite que os usuários gerenciem e orquestrem contêineres em grande escala, em diferentes ambientes de infraestrutura, como data centers, nuvens públicas e privadas. Com o Kubernetes, os usuários podem implantar aplicativos rapidamente, com alta disponibilidade e resiliência, além de gerenciar o tráfego de rede e balanceamento de carga entre os contêineres. O Kubernetes também oferece recursos avançados, como implantações canário, atualizações automáticas e rollbacks de aplicativos, o que permite uma gestão mais eficiente e segura de aplicativos críticos de negócios. Em resumo, o Kubernetes é uma ferramenta essencial para construir e gerenciar aplicativos escaláveis e altamente disponíveis na era da nuvem [\[2\]](#referências).

### **Helm**
Helm é uma ferramenta de gerenciamento de pacotes para Kubernetes que ajuda a simplificar e automatizar a implantação de aplicativos em contêineres. Ele permite que os usuários definam e instalem pacotes de aplicativos, conhecidos como charts, em um cluster Kubernetes de maneira fácil e repetitiva. Helm também oferece recursos avançados, como a capacidade de atualizar, listar e remover charts, além de integrar-se com outras ferramentas de orquestração, como o Kubernetes Dashboard e o Terraform. Com Helm, os usuários podem padronizar e automatizar a implantação de aplicativos em diferentes ambientes, o que reduz o tempo e o esforço necessários para configurar e gerenciar um cluster Kubernetes. Em resumo, Helm é uma ferramenta importante para gerenciar a complexidade da implantação de aplicativos em Kubernetes, permitindo que os usuários se concentrem no desenvolvimento e na inovação de seus aplicativos [\[3\]](#referências).

### **Apache Cassandra**
Apache Cassandra é um banco de dados NoSQL distribuído, altamente escalável e tolerante a falhas. Ele foi projetado para gerenciar grandes volumes de dados estruturados em vários data centers e na nuvem, oferecendo alta disponibilidade e desempenho constante, mesmo em escala global. Cassandra usa uma arquitetura descentralizada e distribuída, com replicação de dados automática e consistência eventual, o que significa que os dados podem ser gravados e lidos em vários nós simultaneamente. Além disso, Cassandra oferece recursos avançados, como compressão de dados, suporte a transações ACID, e uma linguagem de consulta baseada em SQL, o CQL. Esses recursos tornam o Cassandra uma ferramenta importante para aplicativos que exigem escalabilidade e disponibilidade, como serviços de mensagens, mídias sociais, jogos online e IoT [\[4\]](#referências).

### **Testes de software**
Testes de software são uma prática essencial no desenvolvimento de aplicativos que ajudam a garantir que os aplicativos atendam aos requisitos de qualidade, segurança e desempenho. Eles incluem uma série de atividades que vão desde a identificação de requisitos de teste, planejamento de testes, design de casos de teste, execução de testes, avaliação de resultados e relatórios de bugs. Existem vários tipos de testes de software, incluindo testes funcionais, testes de integração, testes de desempenho, testes de segurança e testes de aceitação do usuário, entre outros. A adoção de uma estratégia de teste sólida pode ajudar a reduzir o risco de bugs e falhas no aplicativo, melhorar a eficiência do desenvolvimento e aumentar a satisfação do usuário final [\[5\]](#referências).

### **Sistemas Distribuídos**
Sistemas distribuídos são sistemas de software que consistem em múltiplos componentes independentes, que podem ser executados em diferentes computadores e se comunicam entre si para realizar uma tarefa específica. Eles são projetados para lidar com grandes volumes de dados, lidar com falhas e serem escaláveis, permitindo que os aplicativos sejam distribuídos em várias máquinas para aumentar a capacidade de processamento. Alguns exemplos de sistemas distribuídos incluem aplicativos de comércio eletrônico, redes sociais, sistemas bancários e de gerenciamento de estoque. A construção de sistemas distribuídos requer uma compreensão profunda de arquiteturas de software, protocolos de rede, segurança, gerenciamento de recursos e balanceamento de carga, entre outros conceitos. Além disso, os sistemas distribuídos podem ser difíceis de depurar e testar, tornando a construção de aplicativos escaláveis e tolerantes a falhas um desafio para os desenvolvedores [\[6\]](#referências).

</details></h4>

### **Projetos Integradores durante a graduação**
Durante a graduação, foram desenvolvidos projetos integradores, os quais visam solucionar problemas do mundo real, utilizando os conhecimentos adquiridos durante o curso. A seguir, serão descritos todos esses projetos, incluindo detalhes sobre o problema enfrentado, a solução proposta (e entregue), e os aprendizados obtidos em cada um deles.

<h4><details id="projeto-1" open>
<summary>Projeto 1: 1º Semestre de 2021</summary>

<h3 id="parceiro-p1">Parceiro Acadêmico</h3>
Fatec

<h3 id="objetivo-p1">Objetivo do Projeto</h3>

Projeto consistia em criar uma assistente virtual feito em python. Entre os requisitos estão:
  - Responder a comando de voz ou sons específicos (palma, estalar de dedos, etc.); 
  - Possuir no mínimo 8 ações distintas e de natureza distintas; 
  - Ser mobile, web ou desktop; - Retornar o comando em qualquer forma (som, texto ou ação); 
  - Ter um contexto específico de aplicação; 
  - Não pode usar 100% de APIs prontas e disponíveis no mercado, seja gratuita ou não; 
  - Não pode utilizar de plataforma de implementação de terceiros, seja gratuita ou não;

<h3 id="tecnologias-p1">Tecnologias Utilizadas</h3>

### **Banco de Dados**: SqLite
Foi utilizado o SqLite para guardar informações de comparação e quando é
realizado uma consulta ou uma comparação, é feito uma query no Banco.

### **Back-end**: Python
Para relização da API foi utilizado a linguagem Python, com algumas bibliotecas, são elas:
 - speech_recognition (Para reconhecimento de voz);
 - pyttsx3 (Para síntese de texto em voz);
 - requests (Para realizar requisições na web);
 - BeautifulSoup (Para analisar documentos HTML);
 - Sqlite (Para criar um **Banco de Dados** local).

<h3 id="ferranentas-p1">Ferramentas PyCharm, Visual Studio Code, GitHub e Figma</h3>

<h3 id="contribuições-p1">Contribuições pessoais</h3>

- <h4 id="funções-voz-p1">Funções que reconhecem voz e transformam em texto</h4>

    ```python
    reproducao = pyttsx3.init()

    def sai_som(mensagem, imprimir=True):
        if imprimir:
            print(mensagem)
        reproducao.say(mensagem)
        reproducao.runAndWait()
    ```

    A função ```sai_som()``` recebe uma mensagem e através da lib *pyttsx3* é reproduzido o som utilizando a voz
    do google, além disso, atráves da da variável booleana ```imprimir``` é possíbel definir se a mensagem será printada
    nos logs do serviço. Por ser uma função genérica, é utilizada em várias partes do produto.

    <details><summary>Função assistente</summary>

    ```python
    def assistente():
        sai_som('Oi, qual é o seu nome?')
        user_name = ''
        
        while True:
            resposta_erro_aleatoria = choice(lista_erros)
            rec = sr.Recognizer()

            with sr.Microphone() as s:
                rec.adjust_for_ambient_noise(s)

                while True:
                    try:
                        audio = rec.listen(s)
                        user_name = rec.recognize_google(audio, language ='pt') 
                        break
                    except sr.UnknownValueError:
                        sai_som(resposta_erro_aleatoria)
                break
    ```
    </details>

    A função ```assistente()``` é a matriz do produto, onde é captada a informação dita pelo cliente utilizando o microfone, no caso 
    a primeira parte recebe o nome, que será armazenada na variável *user_name*, que é utilizada em toda a instância de sessão.

    <details><summary>Recognizer</summary>

    ```python
    rec = sr.Recognizer()
    
    with sr.Microphone() as s:
        rec.adjust_for_ambient_noise(s)
        sair = False
        while not sair:
            menu(user_name)
            try:
                resposta_erro_aleatoria = choice(lista_erros)
                audio = rec.listen(s)
                entrada = rec.recognize_google(audio, language ='pt')
                print('{}: {}'.format(user_name, entrada))

                #Funções
                if '<funcionalidade_desejada>' in entrada:
                    entrada = entrada.replace('<funcionalidade_desejada>',' ')
                    resposta = <funcionalidade_desejada>()
                    
                    sai_som('{}'.format(resposta))       
   
                if 'sair' in entrada:
                    sair = True
                                                                
            except sr.UnknownValueError:
                sai_som(resposta_erro_aleatoria)
    ```

    Posterior ao recebimento do nome, o usuário é levado a um menu que mostra as funcionalidades implementadas,
    onde terá de escolher uma, para cada função é executado um redirecionamento:

    ```python
    if '<funcionalidade_desejada>' in entrada:
        entrada = entrada.replace('<funcionalidade_desejada>',' ')
        resposta = <funcionalidade_desejada>()
        
        sai_som('{}'.format(resposta)) 
    ```
    </details>

    Todas as funcionalidades foram divididas em arquivos separados e importadas na matriz e chamadas quando a entrada era 
    igual a flag que foi atrelada a ela.

- <h4 id="requisições-p1">Requisição e interpretação de dados vindos da web</h4>

    <details><summary>Função cotação</summary>

    ```python
    requisição = requests.get('https://economia.awesomeapi.com.br/all')

    cotação = requisição.json()
    def cotacao():
        sai_som('''
            Bem-vindo(a) a cotação do dia!
            Atualmente temos o valor atual das seguintes moedas:
            Dólar - Euro - Libra e Bitcoin!
        ''')
        sai_som('Qual a moeda que deseja cotação?: ')
        Valor_moeda = str(input('')).strip().upper()

        if Valor_moeda == '<moeda_desejada>':
            sai_som('Cotação do Dolar')
            sai_som('Moeda: ' + cotação ['<moeda_desejada_sigla>'] ['name'])
            sai_som('Data: ' + cotação ['<moeda_desejada_sigla>'] ['create_date'])
            sai_som('Valor Atual R$: ' + cotação ['<moeda_desejada_sigla>']['bid'])
    ```
    </details>

    A função ```cotacao()``` é responsável por coletar os valores de cotação de moedas, passar para 
    o formato json e retornar a informação da moeda de acordo com a requisição do usuário, 

- <h4 id="tratamento-p1">Tratamento de erro</h4>

    <details><summary>Padrões de retorno</summary>

    ```python
    lista_erros = [
        'Não entendi nada, repita',
        'Esse erro me custou R$0,97 centavos',
        'Sempre que você errar a fala\n EU VOU ESTAR LÁ\n'

    ]

    conversas = {
        'Olá' : 'Oi, tudo bem?',
        'Tudo, e você?' : 'Estou bem, obrigado'

    }

    comandos = {
        'Desligar' : 'Desligando',
        'Reiniciar' : 'Reiniciando'

    }
    ```
    </details>

    Para realizar o tratamento de erros, foi necessário definir configurações no arquivo ```config.py```
    para padronizar retorno de falar, o que faz com que o assistente retorne frases pré-definidas de acordo
    com o input do usuário.

    ```python
    except sr.UnknownValueError:
        sai_som(resposta_erro_aleatoria)
    ```

<h3 id="aprendizados-p1">Aprendizados Efetivos</h3>

Sendo este o primeiro projeto em que se trabalhou, não apenas na Fatec, mas também na área de programação em geral, exigiu um estudo intenso. Durante o projeto, foi adquirido conhecimento sobre o funcionamento de linguagens interpretadas e compiladas, como iniciar um projeto do zero, como lidar com dados provenientes da web e utilizá-los no sistema de acordo com as solicitações feitas pelo usuário, além de definir o escopo das funções.

</details></h4>

<h4><details id="projeto-2" open>
<summary>Projeto 2: 2º Semestre de 2021</summary>

<h3 id="parceiro-p2">Parceiro Acadêmico</h3>
Necto Systems

<h3 id="objetivo-p2">Objetivo do Projeto</h3>

Desenvolvido para uma aplicação de coleta de informações do servidor para geração de série histórica. A missão é desenvolver uma aplicação para coletar métricas periodicamente de um ou mais Sistemas Gerenciadores de **Banco de Dados** remoto. Através desta ferramenta o usuário terá informações para tomar decisões quanto a necessidade de manutenções, balanceamento e aumento de capacidade e melhoria no seus SGBDs, databases e na sua infra (Servidores).

Requisitos Funcionais:

  - Registros periódicos de métricas (diariamente / hora);
  - Disponibilidade de dados coletados em tempo real;
  - Histórico de métricas;
  - Relatórios com as métricas e valores limites atingidos durante a operação;
  - Cadastros de dados de conexão dos SGBDs (acesso a estatísticas por tabela).

Requisitos Não Funcionais:
  - Linguagem Java;
  - **Banco de Dados** Relacional.

<h3 id="tecnologias-p2">Tecnologias Utilizadas</h3>

### **Banco de Dados**: Postgress
Como pedido pelo cliente, foi utilizado o Postgress e todo o software for desenhado de acordo com os mecanismos
do Postgress.

### **Back-end**: Java
Para relização da API foi utilizado a linguagem Java, com algumas bibliotecas, são elas:
  - java.sql (Para fazer operações no **Banco de Dados**);
  - java.io (Para manipular entrada e saída de arquivos);
  - java.util (Para utilizar toda a estrutura de dados fornecida pelo Java);
  - java.text (Para formatar entrada e saída de dados)

<h3 id="ferramentas-p2">Ferramentas: Intellij, Eclipse, Visual Studio Code, GitHub e Figma</h3>

<h3 id="contribuições-p2">Contribuições pessoais</h3>

- <h4 id="tratamento-p2">Tratamento de Erros</h4>

    <details><summary>SQLRunTimeException</summary>

    ```java
    public class SQLRunTimeException extends RuntimeException {

        private static final long serialVersionUID = 1L;

        public SQLRunTimeException() {

        }

        public SQLRunTimeException(String message) {
            super(message);

        }

        public SQLRunTimeException(Throwable cause) {
            super(cause);

        }

        public SQLRunTimeException(String message, Throwable cause) {
            super(message, cause);

        }

        public SQLRunTimeException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) {
            super(message, cause, enableSuppression, writableStackTrace);

        }
    }
    ```
    </details>

    Em algumas operações, é comum os erros voltarem de maneira não estruturada, para facilitar a leitura foi criado então essa forma de tratamento de exception para que o erro fosse mais fácil de se ler e compreensível [\[7\]](#referências).

- <h4 id="leitura-p2">Leitura de Dados Passados pelo Usuário</h4>

    <details><summary>Leitor</summary>

    ```java
    public class Leitor implements AutoCloseable {

        public Scanner scanner;

        public Leitor() {
            scanner = new Scanner(System.in);
        }

        public int getValor() {
            scanner.reset();
            int op = Integer.valueOf(scanner.nextLine());
            return op;
        }

        public String getTexto() {
            scanner.reset();
            String t = scanner.nextLine();
            return t;
        }

        @Override
        protected void finalize() throws Throwable {
            close();
        }

        @Override
        public void close() throws Exception {
            scanner.close();
        }
    }
    ```
    </details>

    Em outra classe do sistema é definida um menu, e para utilizar é necessário leitura do teclado, para isso foi definido o ```Leitor```, com alguns métodos para garantir a eficácia, e que torna possível a utilização de maneira bem estruturada.

- <h4 id="metrica-p2">Métrica de Tamanho de Banco de Dados</h4>

    <details><summary>Obter tamanho do banco</summary>

    ```java
    @SuppressWarnings("unused")
	public void tamanhoBancos() {
		ObterMetricas obterMetricas3 = new ObterMetricas(loginModel);
		List<TamanhoBancos> tamanhoBancos1 = obterMetricas3.TamanhoBanco();

		for (TamanhoBancos tamanhoBancos : tamanhoBancos1) {
			String nome = tamanhoBancos.getNome();
			String size = tamanhoBancos.getTamanho();
			String date = tamanhoBancos.getData();
		}
	}
    ```
    </details>

    Para a análise de algumas métricas, foi feito a implementação do método ```tamanhoBancos()``` que retorna uma formatação com o
    nome, tamanho e dados do banco.

    <details><summary>Coleta de métricas</summary>

    ```java
    public ArrayList<TamanhoBancos> TamanhoBanco() {

		String sql = "SELECT pg_database.datname, pg_size_pretty(pg_database_size(pg_database.datname)),current_timestamp(0) AS data FROM pg_database;";

		try {
			iniciarConexao();
			PreparedStatement pesquisa = con.prepareStatement(sql);
			ResultSet result = pesquisa.executeQuery();
			ArrayList<TamanhoBancos> lista = new ArrayList<TamanhoBancos>();

			String query = "INSERT INTO TamanhoBanco (datname,pg_size_pretty,data)VALUES (?, ?, ?)";
			PreparedStatement st = in.prepareStatement(query);

			while (result.next()) {
				TamanhoBancos tamTab = new TamanhoBancos();

				tamTab.setNome(result.getString("datname"));
				tamTab.setTamanho(result.getString("pg_size_pretty"));
				tamTab.setData(result.getString("data"));
				lista.add(tamTab);

				st.setString(1, tamTab.getNome());
				st.setString(2, tamTab.getTamanho());
				st.setString(3, tamTab.getData());
				st.executeUpdate();
			}
			return lista;
		} catch (SQLException e) {
			throw new SQLRunTimeException(e.getMessage(), e);
		} finally {
			desconecta();
		}
	}
    ```
    </details>

    Foi feito também um fluxo onde conecta a aplicação no **Banco de Dados** e para cada Banco dentro do SGBD realiza a operação de coletar e armazenar as informações, posterior a isso, é retornado a lista e desconecta do **Banco de Dados**.

<h3 id="aprendizados-p2">Aprendizados Efetivos</h3>

Sendo este o primeiro projeto em que se trabalhou com Java, não apenas na Fatec, mas na área de programação em geral, foi necessário realizar estudos intensos. Durante o projeto, foi adquirido conhecimento sobre o funcionamento do Java, como estabelecer conexão com um banco de dados, como tratar dados provenientes do SGBD e utilizá-los no sistema de acordo com as solicitações feitas pelo usuário, além de definir o escopo das funções.

</details></h4>

<h4><details id="projeto-3" open>
<summary>Projeto 3: 1º Semestre de 2022</summary>

<h3 id="parceiro-p3">Parceiro Acadêmico</h3>
MidAll

<h3 id="objetivo-p3">Objetivo do Projeto</h3>

A empresa MidAll situada no Parque Tecnológico de São José dos Campos, propôs o seguinte desafio baseado na metodologia ágil Scrum. "Temos um problema para criação de promoções em um Ecommerce. Precisamos de uma solução inteligente onde, as mecânicas das promoções sejam feitas de forma flexível e de rápida atualização no sistema".

<h3 id="tecnologias-p3">Tecnologias Utilizadas</h3>

### **Banco de Dados**: Microsoft SQL Server
Como requisitado pela Fatec, foi utilizado um **Banco de Dados** relacional para armazenar o conteúdo das tabelas, como a escolha do BD era opcional foi optado por utilizar o Microsoft SQL Server

### **Back-end**: Java e Spring Boot
Para relização da API foi utilizado a linguagem Java (Outro requisito Fatec) e o framework rest Spring Boot 

### **Front-end**: Angular, CSS, Bootstrap
Para construção da interface foi utilizado o Angular, por alguns motivos, ele é um framework que suporta typescript, e segundo a definição da documentação oficial ele oferece todos os recursos do JavaScript e uma camada adicional sobre eles: o sistema de tipos TypeScript [\[8\]](#referências), também foi utilizado o Angular pois um do requisitos do cliente era atualização simultânea de dados, o que é possíbel fazer facilmente com Angular utilizando o recurso two-way data binding [\[9\]](#referências).

<h3 id="ferramentas-p3">Ferramentas: IntelliJ IDEA, Visual Studio Code, GitHub e Figma</h3>

<h3 id="contribuições-p3">Contribuições pessoais</h3>

- <h4 id="exposição-p3">Exposição dos Endpoints das Tabelas e Camada de Serviço</h4>

    <details><summary>CategoryResource</summary>

    ```java
    @RestController
    @RequestMapping(value = "/categories")
    public class CategoryResource {

        @Autowired
        private CategoryService categoryService;

        @Autowired
        private ModelMapper mapper;

        @GetMapping("/{id}")
        public ResponseEntity<?> find(@PathVariable Integer id) {
            Category cat = categoryService.find(id);
            return ResponseEntity.ok().body(cat);
        }

        @PostMapping
        public ResponseEntity<?> insert(@RequestBody Category obj) {
            obj = categoryService.insert(obj);
            URI uri = ServletUriComponentsBuilder.fromCurrentRequest().path("/{id}").buildAndExpand(obj.getId()).toUri();
            return ResponseEntity.created(uri).build();
        }

        @PutMapping("/{id}")
        public ResponseEntity<?> update(@RequestBody Category obj, @PathVariable Integer id) {

            obj.setId(id);
            obj = categoryService.update(obj);
            return ResponseEntity.noContent().build();
        }

        @DeleteMapping("/{id}")
        public ResponseEntity<?> delete(@PathVariable Integer id) {
            categoryService.delete(id);
            return ResponseEntity.noContent().build();

        }

        @GetMapping
        public ResponseEntity<List<CategoryDTO>> findAll() {
            List<Category> list = categoryService.findAll();

            List<CategoryDTO> listDto = list.stream().map(categoryService -> mapper.map(categoryService, CategoryDTO.class))
                    .collect(Collectors.toList());

            return ResponseEntity.ok().body(listDto);


        }

    }
    ```
    </details>

    Foi realizada a exposição de alguns endpoins baseado no modelo básico de dados. Como é possível ver, definindo a classe como um *RestController* e mapeando ela para uma URL desejada estaremos expondo aquele ponto de acesso quando é iniciado o TomCat, realizando a exposição da entidade para que seja acessada via a uma URL na web, com o domínio que requerido [\[10\]](#referências). Nesse caso, tudo que é relacionado a entidade ```Category``` terá seu ponto de acesso nesse endpoint definido, por ele é realizado operações desejadas e as devidas manipulações utilizando os métodos HTTPs para que sejam feitas operações no **Banco de Dados**, na tabela ```Category```.

    <details><summary>CategoryService</summary>

    ```java
    @Service
    public class CategoryService {

        @Autowired
        private CategoryRepository rep;

        public Category find(Integer id) {
            Optional<Category> cat = rep.findById(id);
            return cat.orElseThrow(() -> new ObjectNotFoundException(
                    "Object not found!: Id: " + id + ", Type: " + Category.class.getName()
            ));
        }

        public Category insert(Category obj){
            obj.setId(null);

            if(obj.getName().isEmpty()){
                throw new BadRequestException("Category with empty name");
            }

            for(Category cat : rep.findAll()){
                if(cat.getName().equals(obj.getName()) ){
                    throw new BadRequestException("Category does exist");
                }
            }
            return rep.save(obj);
        }

        public Category update(Category obj){
            find(obj.getId());
            if(obj.getName().equals(findAll())){
                throw new BadRequestException("Name similar to the one already registered");
            }
            return rep.save(obj);
        }

        public void delete(Integer id){
            find(id);
            if(find(id) == null){
                throw new BadRequestException("No ID entered");
            }
            rep.deleteById(id);
        }

        public List<Category> findAll() {
            List<Category> categoryList = rep.findAll();
            if (categoryList.isEmpty()) { //Nenhuma categoria cadastrada
                throw new BadRequestException("No category registered");
            }
            return rep.findAll();
        }
    }
    ```
    </details>

    A camada de serviço é reponsável pelas regras de negócio da aplicação, ou seja, o que define o que a aplicação faz, o comportamento dela [\[11\]](#referências), no exemplo acima são feitos métodos de pesquisa, de inserção, de deleção e update, totalmente personalizados para a entidade em questão, no caso a entidade ```Category```. É importante separar os Controllers dos Services, não apenas por questão de organização, mas para garantir eficiência também, não é recomendado fazer validações e regras de negócio nos controllers, é necessário definir serviços [\[12\]](#referências).

- <h4 id="modelo-p3">Modelo Básico de Dados</h4>

    Foi produzido o modelo básico de dados, que seriam as classes que representam entidades:

    <details><summary>Product Entity</summary>

    ```java
    @Entity
    @Data
    @EqualsAndHashCode(of={"id"})
    @NoArgsConstructor
    public class Product implements Serializable {
        private static final long serialVersionUID = 1L;

        @Id
        @GeneratedValue(strategy= GenerationType.IDENTITY)
        private Integer id;

        private Integer discount;
        private String name;

        private Double price;

        private String description;

        @JsonIgnore
        @ManyToMany
        @JoinTable(
            name = "PRODUCT_CATEGORY",
            joinColumns = @JoinColumn(name = "product_id"),
            inverseJoinColumns = @JoinColumn(name = "category_id")
        )
        private List<Category> categories = new ArrayList<>();

        @ManyToMany(mappedBy = "product")
        private List<ProductPromotion> productPromotions = new ArrayList<>();

        public Product(Integer id, Integer discount, String name, Double price, String description) {
            this.id = id;
            this.discount = discount;
            this.name = name;
            this.price = price;
            this.description = description;
        }


    }
    ```
    </details>

    É possível ver acima um exemplo de como é feito uma entidade utilizando o ```spring-boot```, elas necessitam da anotação ```@Entity``` para serem compreendidas como classes que são representações de entidades/tabelas, é incluído também outras anotações que são colocadas nos atributos para defini-los, cada atributo da classe é uma coluna da tabela [\[13\]](#referências).


- <h4 id="configuração-p3">Módulo de Configurações da Aplicação</h4>

    Houve a necessidade de um módulo responsável por realizar configurações antes da inicialização do TomCat, por isso foi desenvolvido algumas funções que tinham características específicas, como por exemplo a ```WebConfig```, quais URLs poderiam estar acessando o Back-end, quais métodos seriam permitidos e assim por diante, com o intuito de não ter de repetir código em todos os endpoints que fossem implementados.

    <details><summary>Configurações de CORS</summary>

    ```java
    @Configuration
    public class WebConfig {

        @Bean
        public FilterRegistrationBean<CorsFilter> corsFilterFilterRegistrationBean(){
            List<String> all = Arrays.asList("*");
            List<String> teste = Arrays.asList("http://localhost:4200/");

            CorsConfiguration corsConfiguration = new CorsConfiguration();
            corsConfiguration.setAllowedOrigins(teste);
            corsConfiguration.setAllowedHeaders(all);
            corsConfiguration.setAllowedMethods(all);
            corsConfiguration.setAllowCredentials(true);

            UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();

            source.registerCorsConfiguration("/**", corsConfiguration);

            CorsFilter corsFilter = new CorsFilter(source);

            FilterRegistrationBean<CorsFilter> filter = new FilterRegistrationBean<>(corsFilter);

            filter.setOrder(Ordered.HIGHEST_PRECEDENCE);

            return filter;
        }

    }
    ```
    </details>

    A classe acima, define algumas configurações web para o módulo CORS, definindo quais urls poderam realizar requisições para o Back-end. Esse código é necessário para configurar e habilitar o filtro CORS na aplicação Spring Boot. O filtro CORS é usado para controlar quais origens, cabeçalhos e métodos HTTP são permitidos em solicitações feitas a partir de um domínio diferente. Essa configuração é especialmente útil em aplicações que fornecem uma API RESTful e precisam permitir solicitações CORS de clientes em diferentes origens [\[14\]](#referências).

- <h4 id="integração-p3">Integração do Front-end e Back-end Utilizando Typescript</h4>

    <details><summary>ProductService</summary>

    ```typescript
    @Injectable({
    providedIn: 'root'
    })
    export class ProductsService {

    constructor(private http : HttpClient) { }

    insert( product : Product) : Observable<Product>{
        let obj = {
        "discount" : product.discount,
        "name" : product.name,
        "price" : product.price,
        "description" : product.description,
        "categories" : [
            {
                "id": product.categories
            }
        ]

        }
        return this.http.post<Product>('http://localhost:8080/products', obj)

    }


    getProducts() : Observable<any[]> {
        return this.http.get<Product[]>('http://localhost:8080/products')

    }

    getProductById(id : number) : Observable<Product>{
        return this.http.get<any>(`http://localhost:8080/products/${id}`)
    }

    update(id : number, product : Product) : Observable<Product> {
        let obj = {
        "name": product.name,
        "price": product.price,
        "categories": [
            {
                "id": product.categories
            }
        ]

        }
        return this.http.patch<Product>(`http://localhost:8080/products/${id}`, obj)
    }

    delete(product : Product) : Observable<any>{
        return this.http.delete<any>(`http://localhost:8080/products/${product.id}`)
    }
    }
    ```
    </details>

    Foi realizado a integração do serviço em Angular com o Back-end em Spring Boot, através do uso dos services do angular, onde são criados métodos que enviam objetos para as URLs definidas no Back-end de acordo com as regras pre-definidas utilizando o módulo HTTP do Angular [\[15\]](#referências).

- <h4 id="desenvolvimento-p3">Desenvolvimento de Telas Responsivas</h4>

    <details><summary>ProductForm</summary>

    ```html
    <div class="container">
        <form #productForm="ngForm" (ngSubmit)="onSubmit()">

            <div class="row">
                <div class="col-md-12">
                    <div class="alert alert-success" role="alert" *ngIf="success == true">
                        Product saved/updated successfully!
                    </div>

                    <div class="alert alert-danger" role="alert" *ngFor="let erro of errors">
                        {{ erro }}
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-12">
                    <div class="form-group">
                        <label>ID:</label>
                        <input type="text" class="form-control" disabled="true" [(ngModel)]="product.id" name="id">
                    </div>
                </div>
            </div>
            
            <div class="row">
                
                <div class="col-md-6">
                    <div class="form-group">
                        <label>Name:</label>
                        <input type="text" class="form-control" [(ngModel)]="product.name" name="name">
                    </div>
                </div>

                <div class="col-md-6">
                    <div class="form-group">
                        <label>Price:</label>
                        <input type="text" class="form-control" [(ngModel)]="product.price" name="price">
                    </div>
                </div>
                
            </div>

            <div class="row">
                <div class="col-md-6">
                    <div class="form-group">
                        <label>Description:</label>
                        <input type="text" class="form-control" [(ngModel)]="product.description" name="description">
                    </div>
                </div>

                <div class="col-md-6">
                    <div class="form-group">
                        <label>Category:</label>
                        <input type="text" class="form-control" [(ngModel)]="product.categories" name="categories">
                    </div>
                </div>
                
            </div>

            <div class="row">
                <div class="col-md-4">
                    <button type="submit" class="btn btn-success" *ngIf="!product.id" >
                        <i class="fa fa-save"></i>
                        Save Product
                    </button>

                    <button type="submit" class="btn btn-primary" *ngIf="product.id" >
                        <i class="fa fa-sync-alt"></i>
                        Update Product
                    </button>

                    <button type="submit" class="btn btn-danger ml-2" routerLink="/products-list">
                        <i class="fa fa-arrow-alt-circle-left"></i>
                        return
                    </button>
                </div>

            </div>
        
        </form>
    </div>
    ```
    </details>

    Por fim, foi realizado a criação de algumas telas utilizando HTML, Bootstrap e Angular, realizando as análises e implementando recursos do Angular de acordo com a necessidade de cada tela e de cada endpoint ao qual o Front-end iria consumir.

<h3 id="aprendizados-p3">Aprendizados Efetivos</h3>

Durante esse projeto, o autor ainda não tinha muita noção de como funciona o conjunto do Back-end e Front-end, como utilizar os protocolos de comunicação entre serviços feitos em diferentes linguagens, nem quais configurações devem ser feitas tanto no back-end quanto no front-end para garantir uma comunicação controlada e esperada. Nesse contexto, os aprendizados efetivos foram: integração de microservices, modularização de configurações para inicialização do TomCat e estabelecimento de protocolos de comunicação e exposição adequada da aplicação como um todo para a web.

</details></h4>

<h4><details id="projeto-4" open>
<summary>Projeto 4: 2º Semestre de 2022</summary>

<h3 id="parceiro-p4">Parceiro Acadêmico</h3>
Subter

<h3 id="objetivo-p4">Objetivo do Projeto</h3>

Existe um desafio de sincronização dos dados administrativos, financeiros e operacionais relacionados aos serviços prestados pela empresa. A falta de organização dos dados resulta em lentidão no atendimento de chamados e na interpretação confusa dos indicadores comerciais e financeiros.

- Requisitos Funcionais

  - Cadastros de Usuários, Equipamentos e Horários
  - Usuários devem ter perfis diferentes (administrador, suporte, cliente)
  - Registro de chamados
  - Acompanhamento de chamados de ponta a ponta
  - **Front-end** para entrada e interpretação de dados.

- Requisitos Não Funcionais

    - Linguagem Java Web Server-Side (Requisito Exigido Fatec)
    - PL / SQL (Requisito Exigido Fatec)
    - GIT (Requisito Exigido Fatec)
    - Vue.js ou Flutter (Front-end).

<h3 id="tecnologias-p4">Tecnologias Utilizadas</h3>

### **Banco de Dados**: Oracle Cloud
Como requisitado pela Fatec, foi utilizado um **Banco de Dados** Oracle Cloud para armazenar o conteúdo das tabelas.

### **Back-end**: Java e Spring Boot
Para relização da API foi utilizado a linguagem Java e o framework rest Spring Boot.

### **Front-end**: VueJs, CSS, Bootstrap
Para construção da interface foi utilizado o VueJs.

<h3 id="ferramentas-p4">Ferramentas: IntelliJ IDEA, Docker, Visual Studio Code, GitHub e Figma</h3>

<h3 id="contribuições-p4">Contribuições pessoais</h3>

- <h4 id="exposição-p4">Exposição dos Endpoints das Tabelas e Camada de Serviço</h4>

    <details><summary>ChamadoController</summary>

    ```java
    @RestController
    @RequestMapping("/api/chamados")
    public class ChamadoController {

        @Autowired
        private ChamadoService chamadoService;

        @PreAuthorize("hasAnyRole('CLIENT', 'SUPORTE')")
        @GetMapping
        @JsonView(View.ChamadoView.class)
        public List<Chamado> getAllChamados(){

            return chamadoService.getAllChamados();
        }

        @PreAuthorize("hasAnyRole('CLIENT','SUPORTE')")
        @PostMapping
        @ResponseStatus(HttpStatus.CREATED)
        @JsonView(View.ChamadoView.class)
        public Chamado saveChamado(@RequestBody @Valid Chamado chamado){

            return chamadoService.save(chamado);  
        }

        @PreAuthorize("hasAnyRole('CLIENT', 'SUPORTE')")
        @GetMapping("/{id}")
        @JsonView(View.ChamadoView.class)
        public Chamado getChamadoById(@PathVariable Integer id){

            return chamadoService.getChamadoById(id);
        }
        
        @PreAuthorize("hasAnyRole('CLIENT', 'SUPORTE')")
        @PatchMapping("/{id}")
        @JsonView(View.ChamadoView.class)
        public Chamado updateChamadoById(@PathVariable Integer id, @RequestBody Chamado chamado){

            return chamadoService.updateChamadoById(id, chamado);
        }
        
        @PreAuthorize("hasAnyRole('CLIENT', 'SUPORTE')")
        @DeleteMapping("/{id}")
        @JsonView(View.ChamadoView.class)
        public void deleteChamadoById(@PathVariable Integer id){

            chamadoService.deleteChamadoById(id);
        }
        
    }
    ```
    </details>

    Foi realizada a exposição de alguns endpoints baseados no modelo básico de dados. Ao definir a classe como um RestController e mapeá-la para uma URL desejada, é possível expor aquele ponto de acesso ao iniciar o TomCat. A entidade é exposta para ser acessada por meio de uma URL na web, com o domínio desejado. Nesse caso, todas as operações relacionadas à entidade "Chamado" são acessadas por meio desse endpoint definido. Utilizam-se os métodos HTTP para realizar as operações desejadas e as manipulações adequadas, permitindo operações no banco de dados, na tabela ```Chamado``` [\[10\]](#referências).

- <h4 id="modelo-p4">Modelo Básico de Dados</h4>

    Foi realizado o modelo básico de dados, que seria as classes que representam entidades, utilizando como guia a modelagem feita por outro membro do time.

    <details><summary>Chamado Entity</summary>

    ```java
    @Entity(name = "CHAMADO")
    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    @Builder
    public class Chamado implements Serializable{

        private static final long serialVersionUID = 1L;


        @Id
        @GeneratedValue(strategy = GenerationType.IDENTITY)
        @Column(name = "numero_chamado")
        @JsonView({View.ChamadoView.class, View.UsuarioView.class, View.TipoServicoView.class})
        private Integer id;

        @JoinColumn(name="codigo_usuario")
        @ManyToOne(fetch = FetchType.LAZY)
        @JsonView({View.ChamadoView.class})
        private Usuario usuarioChamado;
        
        @JsonView({View.ChamadoView.class, View.UsuarioView.class})
        @ManyToOne()
        @JoinColumn(name = "tipo_servico_codigo")
        private TipoServico tipoChamado;

        @Column(name = "criticidade_chamado", nullable = false)
        @NotEmpty(message = "O Campo criticidade é obrigatório")
        @JsonView({View.ChamadoView.class, View.UsuarioView.class})
        private String criticidadeChamado;

        @Column(name = "data_chamado", nullable = false)
        @JsonFormat(pattern = "dd/MM/yyyy")
        @JsonView({View.ChamadoView.class})
        private LocalDate dataChamado;

        @Column(name = "assunto_chamado", nullable = false, length = 120)
        @NotEmpty(message = "O Campo assunto é obrigatório")
        @JsonView({View.ChamadoView.class, View.UsuarioView.class, View.TipoServicoView.class})
        private String assuntoChamado;

        @Column(name = "descricao_chamado", nullable = false, length = 300)
        @NotEmpty(message = "O Campo descrição é obrigatório")
        @JsonView({View.ChamadoView.class, View.UsuarioView.class})
        private String descricaoChamado;

        @Column(name = "situacao_chamado", nullable = false)
        @NotEmpty(message = "O Campo situação é obrigatório")
        @JsonView({View.ChamadoView.class})
        private String situacaoChamado;

        @Column(name = "solucao_chamado", nullable = false)
        @JsonView({View.ChamadoView.class})
        private String solucaoChamado;

        @Column(name = "encerramento_chamado")
        @JsonFormat(pattern = "dd/MM/yyyy")
        @JsonView({View.ChamadoView.class})
        private LocalDate encerramentoChamado;

        @JoinColumn(name="numero_agendamento")
        @OneToOne(mappedBy = "chamadoAgendamento", cascade = CascadeType.ALL)
        @JsonView({View.ChamadoView.class})
        private Agendamento agendamento;
        
        @PrePersist
        public void presPersist(){
            setDataChamado(LocalDate.now());
        }

    }
    ```
    </details>

    O exemplo acima ilustra a criação de uma entidade utilizando o Spring Boot. As entidades são representações de tabelas e requerem a anotação @Entity para serem reconhecidas como tal. Além disso, existem outras anotações que são aplicadas aos atributos para defini-los. Cada atributo da classe representa uma coluna na tabela [\[13\]](#referências).

- <h4 id="configuração-p4">Módulo de Configurações da Aplicação</h4>

    Houve a necessidade de um módulo responsável por realizar configurações antes da inicialização do TomCat, por isso foi desenvolvido algumas funções que tinham características específicas, como por exemplo a ```WebConfig```, quais URLs poderiam estar acessando o Back-end, quais métodos seriam permitidos e assim por diante, com o intuito de não ter de repetir código em todos os endpoints que fossem implementados.

    <details><summary>Configurações de CORS</summary>

    ```java
    @Configuration
    public class WebConfig {

        @Bean
        public FilterRegistrationBean<CorsFilter> corsFilterFilterRegistrationBean(){
            List<String> all = Arrays.asList("*");
            List<String> teste = Arrays.asList("http://localhost:4200/");

            CorsConfiguration corsConfiguration = new CorsConfiguration();
            corsConfiguration.setAllowedOrigins(teste);
            corsConfiguration.setAllowedHeaders(all);
            corsConfiguration.setAllowedMethods(all);
            corsConfiguration.setAllowCredentials(true);

            UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();

            source.registerCorsConfiguration("/**", corsConfiguration);

            CorsFilter corsFilter = new CorsFilter(source);

            FilterRegistrationBean<CorsFilter> filter = new FilterRegistrationBean<>(corsFilter);

            filter.setOrder(Ordered.HIGHEST_PRECEDENCE);

            return filter;
        }

    }
    ```
    </details>

    A classe acima, define algumas configurações web para o módulo CORS, definindo quais urls poderam realizar requisições para o Back-end. Esse código é necessário para configurar e habilitar o filtro CORS na aplicação Spring Boot. O filtro CORS é usado para controlar quais origens, cabeçalhos e métodos HTTP são permitidos em solicitações feitas a partir de um domínio diferente. Essa configuração é especialmente útil em aplicações que fornecem uma API RESTful e precisam permitir solicitações CORS de clientes em diferentes origens [\[14\]](#referências).


- <h4 id="security-p4">Security</h4>

    <details><summary>JWTAuthenticationFilter</summary>

    ```java
    @Slf4j
    public class JWTAuthenticationFilter extends UsernamePasswordAuthenticationFilter {

        private final AuthenticationManager authenticationManager;

        public JWTAuthenticationFilter(AuthenticationManager authenticationManager){
            this.authenticationManager = authenticationManager;
        }

        @Override
        public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException {
            String email = request.getParameter("email");
            String password = request.getParameter("password");
            log.info("Username is {} and password is {}", email, password);
            UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(email, password);
            log.info("Token {}", authenticationToken);
            return authenticationManager.authenticate(authenticationToken);
        }

        @Override
        protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authentication) throws IOException, ServletException {
            UserDetails user =  (UserDetails)authentication.getPrincipal();
            Algorithm algorithm = Algorithm.HMAC256("secret".getBytes());
            String access_token = JWT.create()
                    .withSubject(user.getUsername())
                    .withExpiresAt(new Date(System.currentTimeMillis() + 60 * 60 * 1000))
                    .withIssuer(request.getRequestURL().toString())
                    .withClaim("roles", user.getAuthorities().stream().map(GrantedAuthority::getAuthority).collect(Collectors.toList()))
                    .sign(algorithm);
            String refresh_token = JWT.create()
                    .withSubject(user.getUsername())
                    .withExpiresAt(new Date(System.currentTimeMillis() + 60 * 60 * 1000))
                    .withIssuer(request.getRequestURL().toString())
                    .sign(algorithm);

            Map<String, String> tokens = new HashMap<>();
            tokens.put("access_token", access_token);
            tokens.put("refresh_token", refresh_token);
            tokens.put("autorizacao", user.getAuthorities().iterator().next().getAuthority());
            response.setContentType(APPLICATION_JSON_VALUE);
            new ObjectMapper().writeValue(response.getOutputStream(), tokens);

        }
    }
    ```
    </details>

    O código acima implementa um filtro de autenticação JWT em uma aplicação web.

    A classe **JWTAuthenticationFilter** é uma subclasse de **UsernamePasswordAuthenticationFilter**, que é usada para autenticar usuários usando seus nomes de usuário e senhas. No método **attemptAuthentication()**, a classe extrai os dados de nome de usuário e senha da requisição HTTP e cria um token de autenticação do tipo **UsernamePasswordAuthenticationToken**. O token de autenticação é então enviado para o **AuthenticationManager**, que valida as credenciais do usuário.

    Se as credenciais do usuário forem validadas com sucesso, o método **successfulAuthentication()** é chamado. Nesse método, um token JWT é criado usando a biblioteca java-jwt. O token contém o nome de usuário, uma data de expiração, um emissor e as permissões do usuário (também chamadas de funções). O token é então adicionado ao objeto Map e enviado como uma resposta HTTP com um status de 200 [\[16\]](#referências).

    <details><summary>JWTAuthorizationFilter</summary>

    ```java
    public class JWTAuthorizationFilter extends OncePerRequestFilter {

        private final ObjectMapper objectMapper = new ObjectMapper();
        private final JWTVerifier verifier = JWT.require(Algorithm.HMAC256("secret".getBytes())).build();
        private final List<String> ignoredPaths = List.of("/auth/login", "/auth/token/refresh");

        protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException {
            if (ignoredPaths.contains(request.getServletPath())) {
                filterChain.doFilter(request, response);
                return;
            }

            String authorizationHeader = request.getHeader(AUTHORIZATION);
            if (authorizationHeader != null && authorizationHeader.startsWith("Bearer ")) {
                try {
                    String token = authorizationHeader.substring("Bearer ".length());
                    DecodedJWT decodedJWT = verifier.verify(token);
                    String username = decodedJWT.getSubject();
                    String[] roles = decodedJWT.getClaim("roles").asArray(String.class);
                    Collection<SimpleGrantedAuthority> authorities = new ArrayList<>();
                    Arrays.stream(roles).forEach(role -> {
                        authorities.add(new SimpleGrantedAuthority(role));
                    });
                    UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(username, null, authorities);
                    SecurityContextHolder.getContext().setAuthentication(authenticationToken);
                    filterChain.doFilter(request, response);
                } catch (JWTVerificationException e) {
                    response.setHeader("error", e.getMessage());
                    response.setStatus(HttpServletResponse.SC_FORBIDDEN);
                    Map<String, String> error = Map.of("error_message", e.getMessage());
                    response.setContentType(MediaType.APPLICATION_JSON_VALUE);
                    try (OutputStream out = response.getOutputStream()) {
                        objectMapper.writeValue(out, error);
                    }
                }
            } else {filterChain.do}
        }
    }
    ```
    </details>

    O código acima é uma implementação de um filtro de autorização baseado em JWT (JSON Web Token). A classe **JWTAuthorizationFilter** extende a classe OncePerRequestFilter, que é um filtro do Spring que garante que o filtro seja executado apenas uma vez por solicitação [\[17\]](#referências).

    A classe tem uma lista de caminhos ignorados, que são as rotas que não precisam ser autenticadas. Quando uma solicitação é feita para um desses caminhos, o filtro é ignorado e o controle é passado para o próximo filtro da cadeia.

    Para as solicitações que não estão na lista de caminhos ignorados, o filtro verifica se a solicitação contém um token JWT válido no cabeçalho de autorização. Se não houver nenhum token JWT no cabeçalho de autorização, a solicitação é passada para o próximo filtro da cadeia. Se houver um token JWT válido, o filtro extrai o nome de usuário e as permissões do token e cria um objeto **UsernamePasswordAuthenticationToken** contendo essas informações. Em seguida, o filtro armazena esse objeto de autenticação no contexto de segurança e passa a solicitação para o próximo filtro da cadeia.

    Se o token JWT for inválido, o filtro retorna um erro 403 Forbidden com uma mensagem de erro JSON no corpo da resposta.

    <details><summary>SecurityConfig</summary>

    ```java
    @Configuration
    @EnableWebSecurity
    @RequiredArgsConstructor
    @EnableGlobalMethodSecurity(prePostEnabled = true)
    public class SecurityConfig extends WebSecurityConfigurerAdapter {

        private static final String[] PUBLIC_MATCHERS = {
        //"/h2-console/**"
        };

        private static final String[] PUBLIC_MATCHERS_GET = {

        };

        private static final String[] PUBLIC_MATCHERS_POST = {
                "/api/usuarios/**",
                "/auth/login/**",
        };

        private final UserDetailsService userDetailsService;
        private final BCryptPasswordEncoder bCryptPasswordEncoder;

        @Override
        protected void configure(HttpSecurity http) throws Exception {

            JWTAuthenticationFilter jWTAuthenticationFilter = new JWTAuthenticationFilter(authenticationManagerBean());
            jWTAuthenticationFilter.setFilterProcessesUrl("/auth/login");

            http.csrf().disable();
            http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);

            http.authorizeRequests()
                    .antMatchers(PUBLIC_MATCHERS)
                    .permitAll()
                    .antMatchers(HttpMethod.GET, PUBLIC_MATCHERS_GET)
                    .permitAll()
                    .antMatchers(HttpMethod.POST, PUBLIC_MATCHERS_POST)
                    .permitAll()
                    .anyRequest()
                    .authenticated();

            http.addFilter(jWTAuthenticationFilter);
            http.addFilterBefore(new JWTAuthorizationFilter(), UsernamePasswordAuthenticationFilter.class);
        }

        @Override
        protected void configure(AuthenticationManagerBuilder auth) throws Exception {
            auth.userDetailsService(userDetailsService).passwordEncoder(bCryptPasswordEncoder);
        }

        @Bean
        public BCryptPasswordEncoder bCryptPasswordEncoder() {
            return new BCryptPasswordEncoder();
        }

        @Bean
        @Override
        public AuthenticationManager authenticationManagerBean() throws Exception {
            return super.authenticationManagerBean();
        }

        @Override
        public void configure(WebSecurity web) throws Exception {
            web.ignoring()
                    .antMatchers("/h2-console/**")
                    .antMatchers(HttpMethod.POST, "/api/usuarios/auth/signup/suporte")
                    .antMatchers(HttpMethod.POST, "/api/usuarios/auth/signup/client")
                    .antMatchers(HttpMethod.GET, "/api/usuarios/auth/token/refresh");
        }
    }
    ```
    </details>

    O código acima implementa a configuração de segurança em uma aplicação Spring Boot. A classe extende a classe WebSecurityConfigurerAdapter, que permite a configuração de regras de segurança da aplicação [\[18\]](#referências).

    O método **configure(HttpSecurity http)** configura as regras de segurança para a aplicação. Por exemplo, as URLs públicas são permitidas para os PUBLIC_MATCHERS, tanto para as solicitações GET quanto para as POST. Qualquer outra solicitação exige autenticação e autorização. O método também adiciona filtros para autenticação e autorização.

    O método **configure(AuthenticationManagerBuilder auth)** configura a autenticação baseada em **UserDetailsService** e **BCryptPasswordEncoder**.

    O método **configure(WebSecurity web)** configura a segurança para os recursos estáticos que não requerem autenticação. Por exemplo, a URL para o console H2 e alguns endpoints que lidam com o registro de usuários.

    Os beans de **BCryptPasswordEncoder** e **AuthenticationManager** são configurados e disponíveis para uso no contexto da aplicação.

    <details><summary>ApplicationUserDetails</summary>

    ```java
    @Service @RequiredArgsConstructor @Transactional @Slf4j
    public class ApplicationUserDetails implements UserDetailsService {

        private final ApplicationUserRepository applicationUserRepository;

        @Override
        public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
            ApplicationUser applicationUser = applicationUserRepository.findByEmail(username);
            if(applicationUser == null){
                log.error("User not found in the database");
                throw new UsernameNotFoundException("User not found in the database");
            }else{
                log.info("User found in the database: {}", username);
            }
            log.info("Username {} and password {}", applicationUser.getEmail(), applicationUser.getPassword());
            return applicationUser;
        }
    }
    ```
    </details>

    O código acima define uma classe chamada **ApplicationUserDetails** que implementa a interface **UserDetailsService**. 

    A interface UserDetailsService é usada pelo Spring Security para carregar informações de usuário durante a autenticação. A implementação ApplicationUserDetails implementa o método loadUserByUsername, que recebe um nome de usuário como parâmetro e retorna um objeto UserDetails que representa as informações do usuário encontrado [\[19\]](#referências).

    O código usa uma instância do ApplicationUserRepository (injetado por meio do construtor) para procurar um ApplicationUser por e-mail (que é considerado o nome de usuário nesse caso). Se o usuário não for encontrado, uma exceção UsernameNotFoundException é lançada. Se o usuário for encontrado, um log é criado com informações de depuração e o objeto ApplicationUser é retornado como UserDetails.

    ```java
    @PreAuthorize("hasAnyRole('CLIENT', 'SUPORTE')")
    @DeleteMapping("/{id}")
    @JsonView(View.ChamadoView.class)
    public void deleteChamadoById(@PathVariable Integer id){

        chamadoService.deleteChamadoById(id);
    }
    ```

    O código acima é um exemplo de como as roles definidas no serviço são interpretadas nos endpoints. Durante o processo de login, ocorre a autenticação e é verificado qual é a role atribuída ao usuário. A role e o token são armazenados na sessão. Ao utilizar o sistema, todos os endpoints expostos são anotados com **@PreAuthorize("hasAnyRole('ROLE', 'ROLE', ...)")**, definindo quais níveis de usuário têm permissão para realizar a operação requisitada.


- <h4 id="jsonview-p4">JsonView</h4>

    Quando são feitas classes relacionadas, como Empresa e Serviço, é comum surgir a necessidade de visualizar esses dados, tanto em uma tabela quanto em outra. No entanto, surge um desafio quando é necessário visualizar dados da empresa juntamente com os serviços relacionados a ela. Se for utilizado uma operação de GET sem configurações adicionais, a requisição entrará em loop devido ao relacionamento e resultará em um erro. Para contornar esse problema, foi optado por utilizar um componente JsonIgnore em um dos atributos de relacionamento da classe, evitando o loop, entretanto ainda houve a dificuldade de não conseguir visualizar esses dados em conjunto. Portanto, foi decidido utilizar o JsonView para resolver esse problema.

    <details><summary>JsonView</summary>

    ```java
    public class View {

        public static class ChamadoView {};

        public static class EmpresaView {};

        public static class EquipamentoView {};

        public static class EquipamentoSerieView {};

        public static class InstalacaoView {};

        public static class ServicoView {};

        public static class TipoServicoView {};

        public static class UsuarioView {};

        public static class AgendamentoView {};

    }
    ```
    </details>

    Essa classe é a referência pro JsonView, cada método representa a abstração que será usada como View para cada tabela,
    e cada atributo da entidade recebera uma anotação para o JsonView respectivo [\[20\]](#referências).

    <details><summary>Usuario Entity</summary>

    ```java
    @Entity(name = "USUARIO")
    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    @Builder
    public class Usuario implements Serializable{

        private static final long serialVersionUID = 1L;

        @Id
        @GeneratedValue(strategy = GenerationType.IDENTITY)
        @Column(name = "codigo_usuario")
        @JsonView({View.UsuarioView.class, View.ChamadoView.class, View.EmpresaView.class})
        private Integer id;

        @JoinColumn(name="codigo_empresa")
        @ManyToOne()
        @JsonView({View.UsuarioView.class})
        private Empresa empresa;

    }
    ```

    </details>

    Nesse código, é possível observar a configuração do JsonView. Em cada atributo da classe, é adicionada a anotação **@JsonView**, que recebe uma chave correspondente ao View da classe. Vale ressaltar que o atributo de relacionamento com a empresa também possui a anotação **@JsonView**. No entanto, não ocorre um erro ao obter os dados devido à definição isolada dos atributos.

    ```java
    @JsonView({View.UsuarioView.class, View.ChamadoView.class, View.EmpresaView.class})
    private Integer id;
    ```

    Utilizando esse exemplo, veja que a primeira anotação de View é a da própria classe Usuario, e logo
    após é definido que outros Views de classes que se relacionam com Usuario podem realizar um get naquele
    atributo, e por isso, mesmo coletando todos os atributos em alguns casos, se a anotação não for colocada
    no relacionamento, não há problema na visualização desses dados.

- <h4 id="docker-p4">Dockerfile</h4>

    Back-end|
    -------|
    ```Dockerfile
    FROM openjdk:11-jdk-slim
    ARG JAR_FILE=target/*.jar
    COPY ${JAR_FILE} app.jar
    RUN bash -c 'touch /app.jar'
    ENTRYPOINT ["java","-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"]
    ```

    Front-end|
    -------|
    ```Dockerfile
    FROM node:lts-alpine
    RUN npm install -g http-server
    WORKDIR /app
    COPY package*.json ./
    RUN npm install
    COPY . .
    RUN npm run build
    EXPOSE 4200
    CMD [ "http-server", "dist" ]
    ```

    Por fim, o Dockerfile foi configurado para ambos os serviços, permitindo gerar as imagens e utilizá-las como containers. Dessa forma, não é necessário mais nada além do Docker Engine para executá-los.

<h3 id="aprendizados-p4">Aprendizados Efetivos</h3>

Durante esse projeto, o autor não possuía uma ampla noção de como definir níveis de acesso e adequar regras de segurança para serem utilizadas em todo o sistema, visando garantir uma aplicação com um nível adequado de segurança e proteção. Também não tinha conhecimento sobre como otimizar a entrada de dados e realizar filtragens usando o **JsonView**, nem sobre como configurar imagens para posterior uso com um banco de dados na nuvem. Portanto, entende-se que os aprendizados efetivos obtidos foram baseados na definição de níveis de acesso e configuração de uma camada de serviços responsável por autenticação e autorização, na definição de filtros de dados e na construção de imagens para utilização com um banco de dados na nuvem.

</details></h4>

<h4><details id="projeto-5" open>
<summary>Projeto 5: 1º Semestre de 2023</summary>

<h3 id="parceiro-p5">Parceiro Acadêmico</h3>
MidAll

<h3 id="objetivo-p5">Objetivo do Projeto</h3>
A MidAll nasceu para simplificar a jornada de evolução do seu negócio, visando alcançar qualquer visão estratégica. A missão é preparar negócios para o futuro em uma nova era de disrupções de mercado somadas aos desafios pós pandemia. A empresa acredita que Tecnologia, Dados e Inovação orientados para a geração de valor ao cliente são o ambiente de negócios perfeito para promissores resultados.
O objetivo é criar uma aplicação orquestradora de transferência automática de arquivos entre sistemas de armazenamento online. Por meio de uma interface minimalista e interativa, o usuário deve conseguir cadastrar suas credenciais e configurar transferências conforme sua necessidade, dando início a jornada de download e upload entre os storages.

<h3 id="tecnologias-p5">Tecnologias Utilizadas</h3>

<img src="https://img.shields.io/badge/-Vue.js-4FC08D?logo=Vue.js&logoColor=white&style=for-the-badge" alt="badge"> 
<img src="https://img.shields.io/badge/-Flask-000000?logo=Flask&logoColor=white&style=for-the-badge" alt="badge">  
<img src="https://img.shields.io/badge/-MySQL-4479A1?logo=MYSQL&logoColor=white&style=for-the-badge" alt="badge">
<img src="https://img.shields.io/badge/-Docker-2496ED?logo=Docker&logoColor=white&style=for-the-badge" alt="badge">
<img src="https://img.shields.io/badge/-GitHub%20Actions-2088FF?logo=GitHub-Actions&logoColor=white&style=for-the-badge" alt="badge">
<img src="https://img.shields.io/badge/-Kubernetes-326CE5?logo=Kubernetes&logoColor=white&style=for-the-badge" alt="badge">

<h3 id="ferramentos-p5">Ferramentas</h3>

<h3 id="contribuições-p5">Contribuições pessoais</h3>

- <h4 id="google-p5">Google Drive API</h4>

    - <h5 id="download-p5">Download</h5>

        <details><summary>Fazer Download de Arquivo</summary>

        ```python
        def download_file(file_id, file_name, token):
            try:
                file_url = f"https://www.googleapis.com/drive/v3/files/{file_id}?alt=media"
                start_time = time.time()
                response = requests.get(
                    file_url, headers={"Authorization": f"Bearer {token}"}, stream=True
                )
                if not os.path.exists("./downloads/google"):
                    os.makedirs("./downloads/google")

                output_file = os.path.join("./downloads/google", file_name)
                total_time = None
                with open(output_file, "wb") as output:
                    for chunk in response.iter_content(chunk_size=1024):
                        if chunk:
                            output.write(chunk)
                            total_time = time.time() - start_time
                file_size = os.path.getsize(output_file)
                return make_response(
                    jsonify({"title": file_name, "time": total_time, "size": file_size}), 200
                )
            except Exception as e:
                return make_response(jsonify({"error": f"download error: {e}"}), 500)
        ```

        Essa é uma função Python que realiza o download de um arquivo específico do Google Drive. Ela usa a biblioteca requests para fazer uma chamada de API, definindo o ID do arquivo, o nome do arquivo e o token de autorização. A função cria um diretório de download caso não exista e define o caminho de saída para o arquivo baixado. Em seguida, ela baixa os dados do arquivo em chunks, escrevendo-os em um arquivo de saída. Se o download for bem-sucedido, a função retorna informações sobre o arquivo baixado, incluindo o nome, o tempo total de download e o tamanho em bytes. Se ocorrer um erro, a função retorna uma mensagem de erro JSON com um código de status 500.

        </details>

    - <h5 id="upload-p5">Upload</h5>

        <details><summary>Fazer Upload de Arquivo</summary>

        ```python
        def upload_file(file_name, token, origin):
            try:
                url = "https://www.googleapis.com/drive/v2/files"
                data = {
                    "title": file_name,
                    "mimeType": getMymetype("./downloads/google/" + file_name)[0],
                    "description": "Powered by Cloud-in",
                }
                output_file = os.path.join("./downloads/google", file_name)
                start_time = time.time()
                req = requests.post(
                    url, headers={"Authorization": f"Bearer {token}"}, data=json.dumps(data)
                )
                file_id = req.json()["selfLink"].split("/")[-1]
                req_content = (
                    "https://www.googleapis.com/upload/drive/v2/files/"
                    + file_id
                    + "?uploadType=media"
                )
                with open("./downloads/" + origin + "/" + file_name, "rb") as file:
                    content = BytesIO(file.read())
                req = requests.put(
                    req_content, headers={"Authorization": f"Bearer {token}"}, data=content
                )
                total_time = time.time() - start_time
                file_size = os.path.getsize(output_file)
                os.remove("./downloads/" + origin + "/" + file_name)
                return make_response(
                    jsonify({"title": file_name, "time": total_time, "size": file_size}), 200
                )
            except Exception as e:
                return make_response(jsonify({"error": f"upload error: {e}"}), 500)
        ```

        Essa função Python é responsável pelo upload de um arquivo para o Google Drive. Ela recebe como entrada o nome do arquivo, o token de autorização e o diretório de origem do arquivo. A função define o título, o tipo MIME e a descrição do arquivo e envia uma solicitação POST para criar um novo arquivo no Google Drive. Em seguida, ela extrai o ID do arquivo recém-criado e constrói uma URL de upload para enviar os dados do arquivo. A função abre o arquivo de origem e lê seu conteúdo em um objeto BytesIO. Em seguida, ela envia uma solicitação PUT com o objeto BytesIO como carga útil e o token de autorização no cabeçalho. Se o upload for bem-sucedido, a função retorna informações sobre o arquivo carregado, incluindo o nome, o tempo total de upload e o tamanho em bytes. A função também exclui o arquivo de origem após o upload. Se ocorrer um erro, a função retorna uma mensagem de erro JSON com um código de status 500.

        </details>
    
    - <h5 id="list-p5">Listar Arquivos</h5>

        <details><summary>Listar todos os arquivos</summary>

        ```python
        def list_files():
            try:
                token = request.headers.get("token")
                url = "https://www.googleapis.com/drive/v3/files"
                headers = {"Authorization": f"Bearer {token}"}
                params = {"pageSize": 1000, "fields": "nextPageToken, files(id, name, size)"}
                files = []
                next_page_token = True
                while next_page_token:
                    response = requests.get(url, headers=headers, params=params)
                    json_response = response.json()
                    files.extend(json_response["files"])
                    next_page_token = json_response.get("nextPageToken", None)
                    params["pageToken"] = next_page_token
                return make_response(jsonify({"result": files}), 200)
            except Exception as e:
                return make_response(jsonify({"error": f"list files error: {e}"}), 500)
        ```

        Essa função Python faz uma chamada de API para o Google Drive e lista todos os arquivos do usuário autenticado. Ele usa a biblioteca requests para fazer a chamada de API e define parâmetros de consulta para especificar o tamanho máximo de página dos resultados e os campos a serem incluídos na resposta da API. A função percorre todas as páginas de resultados da API e armazena os arquivos em uma lista. Se a chamada da API for bem-sucedida, a função retorna uma lista de arquivos em formato JSON com um código de status 200. Se ocorrer um erro, a função retorna uma mensagem de erro JSON com um código de status 500.

        </details>

        <details><summary>Listar todas as pastas ativas no root</summary>

        ```python
        def list_folders():
            try:
                token = request.headers.get("token")
                url = "https://www.googleapis.com/drive/v3/files"
                headers = {"Authorization": f"Bearer {token}"}
                params = {
                    "q": "mimeType='application/vnd.google.apps.folder' and trashed=false and 'root' in parent",
                    "fields": "nextPageToken,files(id,name)",
                    "pageSize": 1000,
                }
                folders = []
                next_page_token = True
                while next_page_token:
                    response = requests.get(url, hearders=headers, params=params)
                    json_response = response.json()
                    folders.extend(json_response["files"])
                    next_pag_token = json_response.get("nextPageToken", None)
                    params["page Token"] = next_pag_token
                    return make_response(jsonify({"result": folders}), 200)
            except Exception as e:
                return make_response(jsonify({"error": f"list folder error:{e}"}, 500))
        ```

        Esta é uma função que lista as pastas no Google Drive do usuário autenticado pelo token fornecido no cabeçalho da solicitação. A função envia uma solicitação GET para a API do Google Drive com os parâmetros apropriados para recuperar uma lista de pastas que atendam aos critérios especificados na cláusula "q" dos parâmetros. O resultado é uma lista de dicionários, onde cada dicionário representa uma pasta e contém seu ID e nome. A lista completa é retornada como uma resposta JSON com status HTTP 200, a menos que ocorra uma exceção, caso em que a resposta JSON com um erro e status HTTP 500 são retornados.

        </details>

    - <h5 id="padronização-p5">Padronização de Retornos</h5>

        ```python
            return make_response(jsonify({"result": folders}), 200)
        except Exception as e:
            return make_response(jsonify({"error": f"list folder error:{e}"}, 500))
        ```

        Durante o desenvolvimento foi identificado a necessidade de padronizar respostas para o Front-end, portanto foi realizado esse retorno nas funções e um ErrorHandle.

    - <h5 id="config-p5">Config Errors</h5>

        ```python
        def config_error(app):
            @app.errorhandler(Exception)
            def handle_exception(e):
                """Return JSON instead of HTML for HTTP errors."""
                response = e.get_response()
                response.data = json.dumps(
                    {
                        "code": e.code,
                        "name": e.name,
                        "description": e.description,
                    }
                )
                response.content_type = "application/json"
                return response
        ```

        Além de retornar respostas padrões para o Front-end, também foi necessário realizar um ErrorHandler para mapear todo tipo de erro e padronizar a resposta de maneira que o Front-end possa lidar com mais facilidade.

- <h4 id="ci-p5">Continuous Integration</h4>

    - <h5 id="ts-p5">Testes de Software</h5>

        <details><summary>test_list_files_valid_token</summary>

        ```python
        @mock.patch("requests.get")
        def test_list_files_valid_token(mock_get):
            mock_get.return_value.json.return_value = {
                "files": [
                    {"id": "123", "name": "file1", "size": 100},
                    {"id": "456", "name": "file2", "size": 200},
                ]
            }
            client = app.test_client()
            response = client.get("/google/list", headers={"token": "valid_token"})
            assert response.status_code == 200
            assert response.json == {
                "result": [
                    {"id": "123", "name": "file1", "size": 100},
                    {"id": "456", "name": "file2", "size": 200},
                ]
            }
        ```

        Este é um teste unitário para a função list_files() que verifica se a função retorna os arquivos corretamente quando é passado um token válido. O teste utiliza a biblioteca unittest.mock para criar um objeto "mock" para a função requests.get(). O objeto mock é usado para simular o comportamento da função requests.get() sem realmente fazer uma requisição HTTP real. Em seguida, o teste configura o objeto mock para retornar uma resposta simulada contendo uma lista de dois arquivos. O teste então usa um cliente Flask para enviar uma solicitação HTTP GET para a rota "/google/list" com um token de autorização válido. Finalmente, o teste verifica se a resposta HTTP retorna um código de status 200 e se o conteúdo JSON retornado é igual à lista de arquivos simulados. Se ambas as verificações passarem, o teste é considerado bem-sucedido.

        </details>
        
        <details><summary>test_list_files_invalid_token</summary>

        ```python
        def test_list_files_invalid_token():
            client = app.test_client()
            response = client.get("/google/list", headers={"token": "invalid_token"})
            assert response.status_code == 500
        ```

        Este é um teste da função list_files() quando é fornecido um token inválido. O teste é executado usando o cliente de teste do Flask para enviar uma solicitação GET para a rota '/google/list', com o cabeçalho 'token' definido como 'invalid_token'. Em seguida, é feita uma afirmação para verificar se o código de status da resposta é 500 (erro interno do servidor), o que significa que o token fornecido não é válido e não é possível listar os arquivos.

        </details>

        <details><summary>test_download_file</summary>

        ```python
        @mock.patch("requests.get")
        def test_download_file(mock_get):
            mock_get.return_value.iter_content.return_value = [b"test content"]
            mock_get.return_value.status_code = 200
            file_id = "123"
            file_name = "test_file"
            token = "valid_token"

            with app.app_context():
                response = download_file(file_id, file_name, token)
                assert response.status_code == 200
                assert response.json == {
                    "title": file_name,
                    "time": pytest.approx(0, abs=0.1),
                    "size": len(b"test content"),
                }
                assert os.path.exists(f"./downloads/google/{file_name}")
                with open(f"./downloads/google/{file_name}", "rb") as f:
                    assert f.read() == b"test content"
                os.remove(f"./downloads/google/{file_name}")
                assert not os.path.exists(f"./downloads/google/{file_name}")
        ```

        Esse é um teste da função download_file() que verifica se o download de um arquivo do Google Drive é feito corretamente. Para isso, ele utiliza a biblioteca pytest e a biblioteca unittest.mock para criar um objeto mock que simula a resposta da requisição feita pelo requests.get(). Em seguida, a função download_file() é chamada com um file_id, um file_name e um token válidos. O teste verifica se a resposta da função é bem-sucedida (código de status 200), se o tempo retornado é próximo de zero, se o tamanho do arquivo baixado corresponde ao tamanho esperado e se o arquivo foi criado e removido corretamente na pasta de downloads. Esse teste ajuda a garantir que a função download_file() está funcionando corretamente e é uma boa prática de desenvolvimento de software para evitar erros no código em produção.

        </details>

        <details><summary>test_upload_file</summary>

        ```python
        @mock.patch("requests.post")
        @mock.patch("requests.put")
        def test_upload_file(mock_put, mock_post):
            mock_post.return_value.status_code = 200
            mock_post.return_value.json.return_value = {
                "selfLink": "https://www.googleapis.com/drive/v2/files/123"
            }

            mock_put.return_value.status_code = 200

            file_name = "test_file"
            token = "valid_token"
            origin = "google"

            if not os.path.exists(f"./downloads/{origin}"):
                os.makedirs(f"./downloads/{origin}")
            with open(f"./downloads/{origin}/{file_name}", "wb") as f:
                f.write(b"test content")

            with app.app_context():
                response = upload_file(file_name, token, origin)

                assert response.status_code == 200
                assert response.json == {
                    "title": file_name,
                    "time": pytest.approx(0, abs=0.1),
                    "size": len(b"test content"),
                }
                assert not os.path.exists(f"./downloads/{origin}/{file_name}")
        ```

        Esse é um teste de unidade para uma função upload_file() que simula a requisição para upload de um arquivo em um serviço de armazenamento em nuvem. A função utiliza os módulos requests.post e requests.put para simular a criação do arquivo na nuvem e o upload do conteúdo. O teste cria um arquivo de teste na pasta de downloads da aplicação e chama a função com os parâmetros necessários para fazer o upload desse arquivo para o serviço de armazenamento. O teste usa mock.patch para substituir as funções requests.post e requests.put por versões simuladas, que retornam um código de status HTTP 200 para simular uma requisição bem-sucedida. O teste então verifica se a resposta da função está correta, ou seja, se o código de status é 200 e se o JSON retornado possui as informações esperadas do arquivo, como nome, tamanho e tempo de upload. Por fim, o teste verifica se o arquivo de teste foi removido corretamente após a conclusão do upload.

        </details>

        <details><summary>test_autoscale.py</summary>

        ```python
        CHART_DIR = "cloudin-midall"
        CHART_NAME = "cloudin-midall-1.0.0.tgz"
        RELEASE_NAME = "cloudin"
        NAMESPACE = "k8s-test"
        INITIAL_REPLICAS = 1
        FINAL_REPLICAS = 3

        @pytest.fixture(scope="session")
        def setup_teardown():
            subprocess.run(["helm", "package", CHART_DIR])

            config.kube_config.load_kube_config(context="k3d-mycluster")

            api = client.CoreV1Api()
            api.create_namespace(body=client.V1Namespace(metadata=client.V1ObjectMeta(name=NAMESPACE)))

            yield

            subprocess.run(["helm", "uninstall", RELEASE_NAME, "-n", NAMESPACE])

            api.delete_namespace(name=NAMESPACE, body=client.V1DeleteOptions())

        def make_get_requests(url):
            for _ in range(100):
                response = requests.get(url)
                assert response.status_code == 200

        def test_autoscaling(setup_teardown):
            CHART = "{CHART_DIR}/{CHART_NAME}"
            subprocess.run(["helm", "install", RELEASE_NAME, "-n", NAMESPACE, CHART, "--wait"])

            sleep(10)

            api = client.AppsV1Api()
            deployment = api.read_namespaced_deployment(name=RELEASE_NAME, namespace=NAMESPACE)
            assert deployment.spec.replicas == INITIAL_REPLICAS

            threads = []
            for _ in range(1000):
                t = threading.Thread(target=make_get_requests, args=("http://localhost/config/test",))
                threads.append(t)
                t.start()

            for t in threads:
                t.join()

            sleep(60)

            deployment = api.read_namespaced_deployment(name=RELEASE_NAME, namespace=NAMESPACE)
            assert deployment.spec.replicas >= FINAL_REPLICAS
        ```

        O teste de autoscaling apresentado tem como objetivo verificar o funcionamento do dimensionamento automático (autoscaling) em um ambiente Kubernetes. O teste segue os seguintes passos:

        - É definido um conjunto de variáveis que especificam as informações necessárias para o teste, como o diretório do chart, o nome do release, o namespace, o número inicial de réplicas e o número final de réplicas esperado após o autoscaling.
        - É definida uma fixture setup_teardown() que é executada antes e depois do teste. Essa fixture empacota o chart, carrega a configuração do Kubernetes, cria um namespace para o teste e, em seguida, executa o código de teste. Após a conclusão do teste, a fixture desinstala o release e exclui o namespace criado.
        - É definida uma função make_get_requests() que envia 100 solicitações GET para a URL fornecida. O objetivo é simular o tráfego que acionará o autoscaling.
        - O teste em si, test_autoscaling(), inicia a instalação do chart usando o Helm, aguarda um intervalo de tempo para que as réplicas iniciais sejam implantadas e, em seguida, verifica se o número de réplicas é igual ao valor inicial esperado.

        Em seguida, o teste inicia 1000 threads para enviar solicitações GET em paralelo para a URL especificada, simulando um aumento de tráfego. As threads são aguardadas até que todas sejam concluídas. Após um intervalo de espera, o teste verifica novamente o número de réplicas implantadas e verifica se é maior ou igual ao número final de réplicas esperado.O teste geral verifica se o dimensionamento automático está funcionando corretamente, observando se o número de réplicas é ajustado de acordo com o aumento de tráfego simulado.

        </details>

    - Deploy usando Dockerfile

        ```Dockerfile
        FROM python:3.11-bullseye
        COPY ./requirements.txt /app/requirements.txt
        WORKDIR /app
        RUN pip install -r requirements.txt
        COPY . /app
        ENTRYPOINT [ "flask" ]
        CMD [ "run","--host=0.0.0.0","--port=5000"]
        ```

        Um Dockerfile é um arquivo de texto que contém um conjunto de instruções para construir uma imagem Docker. Ele define o ambiente e as configurações necessárias para criar uma imagem Docker reproduzível e portátil. O Dockerfile especifica cada etapa do processo de construção da imagem, desde a escolha da imagem base até a instalação de dependências, cópia de arquivos, configuração de variáveis de ambiente e a definição do comando de inicialização do container. Essas instruções são executadas sequencialmente pelo Docker durante a construção da imagem, resultando em uma imagem final pronta para ser executada em um container Docker. O Dockerfile é uma parte fundamental do processo de construção e implantação de aplicativos em contêineres Docker, pois permite a automação e a padronização da criação de imagens [\[21\]](#referências).

- <h4 id="cd-p5">Continuous Delivery</h4>
    
    <details id="k3d-p5"><summary>K3D Cluster</summary>

    Com o objetivo de criar um ambiente k8s para teste antes de utilizar o cluster AKS, foi realizado a configuração e a documentação do cluster k3d. K3d é uma ferramenta de linha de comando projetada para simplificar o gerenciamento de clusters de Kubernetes localmente. Ele permite criar, implantar e gerenciar clusters Kubernetes em seu ambiente de desenvolvimento ou teste. Com o K3d, você pode provisionar rapidamente clusters Kubernetes leves em contêineres Docker, o que facilita a execução de várias instâncias do Kubernetes em uma única máquina. É uma opção popular para desenvolvedores que desejam testar e depurar aplicativos em um ambiente Kubernetes local [\[22\]](#referências).

    Depois de instalado as dependências, é necessário apenas rodar o seguinte comando:
    ```bash
    k3d cluster create --config k3d-simple-cluster.yaml
    ```

    O guia completo de setup está presente no [repositório do projeto.](https://github.com/DolphinDatabase/Cloudin-backend#readme)

    </details>

    <details id="aks-p5"><summary>AKS Cluster</summary>

    O Serviço de Kubernetes do Azure (AKS) oferece a maneira mais rápida de começar a desenvolver e implantar aplicativos nativos de nuvem no Azure, em datacenters ou na borda com pipelines internos do código para a nuvem e verificadores de integridade. Obtenha gerenciamento e governança unificados para clusters do Kubernetes locais, de borda e multinuvem. Interopere com os serviços de segurança, identidade, gerenciamento de custos e migração do Azure [\[23\]](#referências).

    </details>

    <details id="deployment-p5"><summary>Kubernetes Deployment</summary>

    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
    name: cloudin-midall
    labels:
        app: cloudin-midall
    spec:
    replicas: {{ .Values.replicas }}
    selector:
        matchLabels:
        app: cloudin-midall
    template:
        metadata:
        labels:
            app: cloudin-midall
        spec:
        containers:
            - name: backend
            image: {{ include "cloudin-midall.getImage" . }}
            ports:
                - containerPort: {{ .Values.backend.ports.containerPort }}
            env:
            - name: DATABASE_URL
                value: mysql://dbuser:dbuser@cloudin-midall-mysql:3306/cloudin
    {{ include "cloudin-midall.probeAndResources" .Values.backend.ports.containerPort | nindent 10 }}
    ```

    Um "Deployment" é usado para criar e gerenciar instâncias de aplicativos em um cluster Kubernetes. Ele especifica as configurações para replicação, seleção de pods, modelo de pod e containers associados. No caso utilizado no projeto, o Deployment chamado "cloudin-midall" está sendo configurado para criar um replicaSet com o número de réplicas definido pelo valor definido no values.yaml. O container "backend" é definido com sua imagem e configurações de porta e variável de ambiente.

    Um Deployment é adequado para aplicativos que não possuem estado, ou seja, não armazenam dados persistentes. Ele gerencia a implantação de réplicas de pods de forma controlada, permitindo atualizações, rollback e dimensionamento automático. Os pods criados por um Deployment não possuem identidade única e não mantêm conexões persistentes com o armazenamento [\[24\]](#referências).

    </details>

    <details id="statefulset-p5"><summary>Kubernetes StatefulSet</summary>

    ```yaml
    apiVersion: apps/v1
    kind: StatefulSet
    metadata:
    name: cloudin-midall-mysql
    labels:
        app: cloudin-midall-mysql
    spec:
    serviceName: cloudin-midall-mysql
    replicas: 1
    selector:
        matchLabels:
        app: cloudin-midall-mysql
    template:
        metadata:
        labels:
            app: cloudin-midall-mysql
        spec:
        containers:
            - name: mysql
            image: mysql:latest
            ports:
                - containerPort: 3306
            env:
                - name: MYSQL_ROOT_PASSWORD
                value: "example"
                - name: MYSQL_DATABASE
                value: "cloudin"
                - name: MYSQL_USER
                value: "dbuser"
                - name: MYSQL_PASSWORD
                value: "dbuser"
            resources:
                limits:
                cpu: 100m
                memory: 512Mi
                requests:
                cpu: 80m
                memory: 128Mi
    ```

    Foi definido um "StatefulSet" no Kubernetes para executar uma instância do banco de dados MySQL. O StatefulSet é nomeado como "cloudin-midall-mysql" e possui uma réplica. O serviço associado ao StatefulSet também é chamado de "cloudin-midall-mysql". A definição do pod inclui um container chamado "mysql" que usa a imagem mais recente do MySQL. A porta 3306 é exposta para comunicação. Variáveis de ambiente são configuradas para definir a senha do usuário root do MySQL, o nome do banco de dados, o nome de usuário e a senha do usuário do banco de dados. Restrições de recursos são definidas para limitar o uso de CPU e memória do container.

    Um "StatefulSet" é usado para aplicativos que possuem estado e requerem identidade única e armazenamento persistente para seus pods. Ele fornece garantias de ordem e estabilidade durante a criação, atualização e exclusão dos pods. Cada pod em um StatefulSet é atribuído a um identificador exclusivo e mantém seu próprio estado persistente. Isso é especialmente útil para bancos de dados e outras aplicações que exigem armazenamento persistente e consistência de estado entre os pods [\[25\]](#referências).

    </details>

    <details id="service-ip-p5"><summary>Kubernetes Service ClusterIP</summary>

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
    name: cloudin-midall-mysql
    labels:
        app: cloudin-midall-mysql
    spec:
    type: ClusterIP
    ports:
        - port: 3306
        targetPort: 3306
        protocol: TCP
        name: mysql
    selector:
        app: cloudin-midall-mysql
    ```

    O Service ClusterIP é um tipo de serviço no Kubernetes que expõe um conjunto de pods para comunicação interna dentro do cluster. Ele fornece um endereço IP interno estático para o serviço, permitindo que outros recursos dentro do cluster se conectem a ele. O serviço "cloudin-midall-mysql" é definido como um Service ClusterIP. Ele mapeia a porta 3306 para o targetPort 3306 em protocolo TCP, que é o padrão para comunicação com o banco de dados MySQL. O seletor "app: cloudin-midall-mysql" garante que o Service encaminhe o tráfego para os pods que possuem a mesma etiqueta. Esse tipo de serviço é adequado para comunicação interna e não é acessível de fora do cluster [\[26\]](#referências).

    </details>

    <details id="service-lb-p5"><summary>Kubernetes Service LoadBalancer</summary>

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
    name: cloudin-midall
    labels:
        app: cloudin-midall
    spec:
    type: LoadBalancer
    ports:
    - port: {{ .Values.backend.ports.containerPort }}
        targetPort: {{ .Values.backend.ports.containerPort }}
        protocol: TCP
        name: http
    selector:
        app: cloudin-midall
    ```

    O Service LoadBalancer é um tipo de serviço no Kubernetes que expõe um conjunto de pods para o tráfego externo, permitindo que o aplicativo seja acessado de fora do cluster. Ele provisiona automaticamente um balanceador de carga externo, como um balanceador de carga na nuvem, que distribui o tráfego para os pods do serviço. O serviço "cloudin-midall" é definido como um Service LoadBalancer. Ele mapeia uma determinada porta, definida pelo valor ".Values.backend.ports.containerPort", para o targetPort correspondente. O protocolo especificado é TCP e o nome do serviço é "http". O seletor "app: cloudin-midall" garante que o Service encaminhe o tráfego para os pods com a mesma etiqueta. Esse tipo de serviço é adequado para expor um aplicativo para o tráfego externo, permitindo a acessibilidade de fora do cluster, através do balanceador de carga fornecido pelo ambiente de execução do Kubernetes, como um balanceador de carga na nuvem [\[27\]](#referências).

    </details>

    <details id="hpa-p5"><summary>Kubernetes HorizontalPodAutoscaler</summary>
    
    ```yaml
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    metadata:
    name: cloudin-midall-hpa
    spec:
    scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: cloudin-midall
    minReplicas: 1
    maxReplicas: 5
    metrics:
        - type: Resource
        resource:
            name: cpu
            target:
            type: Utilization
            averageUtilization: 80
    ```

    O HorizontalPodAutoscaler (HPA) é um recurso do Kubernetes que permite o dimensionamento automático do número de réplicas de um Deployment ou outro objeto de escala horizontal. O HPA chamado "cloudin-midall-hpa" está configurado para dimensionar automaticamente o número de réplicas do Deployment "cloudin-midall". O número mínimo de réplicas é definido como 1 e o número máximo como 5. O HPA utiliza métricas para tomar decisões de dimensionamento. A métrica utilizada é a utilização média de CPU, onde o HPA tentará manter a utilização de CPU em torno de 80%. Com base nessa métrica, o HPA aumentará ou diminuirá o número de réplicas do Deployment para atender às demandas de tráfego. Isso permite que o cluster Kubernetes ajuste automaticamente a capacidade de processamento conforme necessário, garantindo um dimensionamento eficiente dos recursos do aplicativo.

    </details>

    <details id="ingress-p5"><summary>Kubernetes Ingress</summary>
    
    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
    name: cloudin-midall
    annotations:
        kubernetes.io/ingress.class: azure/application-gateway
    spec:
    rules:
    - http:
        paths:
        - path: /
            pathType: Prefix
            backend:
            service:
                name: cloudin-midall
                port:
                number: 5000
    ```

    O Ingress é um recurso no Kubernetes que permite a exposição de serviços HTTP e HTTPS externamente ao cluster. O Ingress chamado "cloudin-midall" é definido com a anotação "kubernetes.io/ingress.class" configurada como "azure/application-gateway", indicando que o Ingress será gerenciado pelo Application Gateway do Azure. A especificação do Ingress inclui regras para roteamento do tráfego. No exemplo, há uma única regra que encaminha todo o tráfego HTTP que chega à raiz ("/") para o serviço chamado "cloudin-midall" na porta 5000. O campo "pathType" é definido como "Prefix", o que significa que o Ingress corresponderá a URLs que começam com o caminho especificado. O Ingress permite a configuração flexível do roteamento do tráfego externo para serviços internos no Kubernetes, fornecendo uma camada de controle de acesso e balanceamento de carga [\[29\]](#referências).

    </details>

<h3 id="aprendizados-p5">Aprendizados Efetivos</h3>
Durante o desenvolvido do projeto foi aprendizado a implantar e monitorar clusters kubernetes para produção e para testes, como realizar integração contínua utilizando Github Actions, usabilidade do serviço Amazon S3 e como realizar operações de listener para realizar de sincronização e transferência automáticas sem interferência humana. Além disso, foi realizado testes de integração e de unidade com o GoogleService, S3Service e K8SApi ao qual o autor ainda tinha dúvidas de como funcionavam que durante o semestre foram sanadas e a partir do aprendizado foi desenvolvido uma base mais sólida para futuros trabalhos.

<h3 id="demo-p5">Demonstração das Funcionalidades</h3>

Para acessar a playlist do projeto, clique [aqui](https://www.youtube.com/watch?v=AGRvBq9Xq4U&list=PLUOBqJKbljZsvHbaHWKrQ3z0l9l2Uo_f0):

[<img src="https://user-images.githubusercontent.com/74321890/228991716-687c07f9-3b6a-4cea-b855-677b51b2b20a.svg" width="60%" height="60%">](https://www.youtube.com/watch?v=AGRvBq9Xq4U&list=PLUOBqJKbljZsvHbaHWKrQ3z0l9l2Uo_f0 "Cloud-in vídeo Demonstração")

</details></h4>

### **Conclusões**
O curso de Tecnólogo em Banco de Dados proporcionou uma jornada repleta de aprendizado significativo e experiências valiosas. Ao refletir sobre o percurso deste projeto, fica evidente o quão benéfico foi para o autor, tanto em termos de conhecimento técnico quanto de desenvolvimento pessoal.

No início, o Projeto Integrador representou um primeiro mergulho tanto na Fatec quanto na área de programação em geral. A necessidade de realizar estudos intensos demonstrou o comprometimento do autor em aprender e aplicar conceitos fundamentais. A aquisição de conhecimentos sobre linguagens interpretadas e compiladas, o desenvolvimento a partir do zero e o tratamento de dados da web foram conquistas significativas, moldando uma base sólida para futuros empreendimentos.

A familiarização com Java, uma linguagem muito abordada na faculdade, também é digna de destaque. Através de esforços intensivos, o autor dominou as complexidades da linguagem, explorando a conexão com bancos de dados e o processamento de dados do SGBD de acordo com as necessidades do usuário. Além disso, a definição de escopos funcionais enriqueceu a capacidade de planejamento e design de sistemas.

A evolução não se limitou apenas à linguagem Java, pois o autor também embarcou em uma jornada de descoberta das dinâmicas Back-end e Front-end. Superando desafios de integração de microservices, protocolos de comunicação e exposição adequada da aplicação na web, o aprendizado expandiu-se para abranger uma visão mais holística do desenvolvimento de software.

A importância da segurança e da proteção de dados também emergiu como um aspecto crítico. O autor conquistou uma compreensão profunda sobre a definição de níveis de acesso e a implementação de regras de segurança para garantir a integridade da aplicação. A habilidade de filtrar dados usando o JsonView e a configuração de imagens para um banco de dados na nuvem aprimoraram ainda mais a capacidade de construir aplicações robustas e seguras.

O Projeto Integrador também alavancou o conhecimento prático de tecnologias atuais. A implantação e monitoramento de clusters Kubernetes, integração contínua com o uso do Github Actions e a exploração do Amazon S3 refletem uma compreensão crescente das ferramentas de desenvolvimento modernas. Além disso, a aquisição de competências em operações de sincronização e transferência automáticas, assim como a resolução de dúvidas em relação a serviços como GoogleService, S3Service e K8SApi, solidificaram o conhecimento técnico do autor e o capacitaram para desafios futuros.

Concluindo, o curso de Tecnólogo em Banco de Dados se revelou como um trampolim para um aprendizado rico e profundo. O autor não apenas dominou habilidades técnicas cruciais, mas também desenvolveu a resiliência, a curiosidade e a determinação necessárias para prosperar em um campo em constante evolução. As lições aprendidas ao longo deste projeto não apenas enriqueceram o repertório do autor, mas também estabeleceram uma base sólida para um futuro promissor e repleto de oportunidades no mundo da programação e do desenvolvimento de software.

### **Referências**
[1] - [O que é Docker?](https://aws.amazon.com/pt/docker/#:~:text=Docker%20is%20a%20software%20platform,tools%2C%20code%2C%20and%20runtime.)
<br/>
[2] - [O que é Kubernetes?](https://cloud.google.com/learn/what-is-kubernetes?hl=pt-br#:~:text=Kubernetes%20automates%20operational%20tasks%20of,it%20easier%20to%20manage%20applications.
)
<br/>
[3] - [O que é Helm?](https://helm.sh/)
<br/>
[4] - [Introdução ao Apache Cassandra](https://cassandra.apache.org/_/cassandra-basics.html)
<br/>
[5] - [Importância do Teste de Software](https://www.ibm.com/topics/software-testing#:~:text=Software%20testing%20is%20the%20process,Types%20of%20software%20testing)
<br/>
[6] - [O que são Sistemas Distribuídos?](https://www.splunk.com/en_us/data-insider/what-are-distributed-systems.html#:~:text=A%20distributed%20system%20is%20a,been%20responsible%20for%20the%20task.)
<br/>
[7] - [Exceções e Controle de Erros em Java](https://www.alura.com.br/apostila-java-orientacao-objetos/excecoes-e-controle-de-erros?utm_term=&utm_campaign=%5BSearch%5D+%5BPerformance%5D+-+Dynamic+Search+Ads&utm_source=adwords&utm_medium=ppc&hsa_acc=7964138385&hsa_cam=1560195067&hsa_grp=63243218150&hsa_ad=473952452366&hsa_src=g&hsa_tgt=aud-1030763255023:dsa-1684046743563&hsa_kw=&hsa_mt=&hsa_net=adwords&hsa_ver=3&gclid=Cj0KCQjwuNemBhCBARIsADp74QSaTuMsqlx_54Cvs_N1QWEfRtl9sqOI-bFUhPu_0oQKhuW_DwfDmlAaAta9EALw_wcB)
<br/>
[8] - [TypeScript in 5 minutes](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html)
<br/>
[9] - [Two-Way Data Binding in Angular](https://angular.io/guide/two-way-binding)
<br/>
[10] - [Spring @RestController Documentation](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/bind/annotation/RestController.html)
<br/>
[11] - [Why to Use Service Layer in Spring MVC](https://blog1.westagilelabs.com/why-to-use-service-layer-in-spring-mvc-5f4fc52643c0)
<br/>
[12] - [Spring Boot Microservices: Coding Style Guidelines and Best Practices](https://medium.com/codex/spring-boot-microservices-coding-style-guidelines-and-best-practices-1dec229161c8#b0ab)
<br/>
[13] - [Accessing Data with JPA - Spring Guide](https://spring.io/guides/gs/accessing-data-jpa/)
<br/>
[14] - [Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)
<br/>
[15] - [Creating Injectable Services in Angular](https://angular.io/guide/creating-injectable-service)
<br/>
[16] - [JwtAuthenticationFilter - Atlassian Connect Spring Boot Core](https://javadoc.io/doc/com.atlassian.connect/atlassian-connect-spring-boot-core/2.0.0/com/atlassian/connect/spring/internal/auth/jwt/JwtAuthenticationFilter.html)
<br/>
[17] - [OncePerRequestFilter - Spring Framework](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/filter/OncePerRequestFilter.html)
<br/>
[18] - [WebSecurityConfigurerAdapter - Spring Security](https://docs.spring.io/spring-security/site/docs/5.7.0-M2/api/org/springframework/security/config/annotation/web/configuration/WebSecurityConfigurerAdapter.html)
<br/>
[19] - [UserDetailsService and Password Encoding - Spring Security](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/user-details-service.html)
<br/>
[20] - [Jackson Annotations for Controllers - Spring Framework](https://docs.spring.io/spring-framework/reference/web/webmvc/mvc-controller/ann-methods/jackson.html)
<br/>
[21] - [Docker Build Reference](https://docs.docker.com/engine/reference/builder/)
<br/>
[22] - [k3d: Easily Run Kubernetes Locally](https://k3d.io/v5.5.2/)
<br/>
[23] - [Azure Kubernetes Service](https://azure.microsoft.com/en-us/products/kubernetes-service)
<br/>
[24] - [Kubernetes Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)
<br/>
[25] - [Kubernetes StatefulSets](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)
<br/>
[26] - [Cluster IP Allocation in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/cluster-ip-allocation/)
<br/>
[27] - [Kubernetes Service LoadBalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer)
<br/>
[28] - [Horizontal Pod Autoscale in Kubernetes](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
<br/>
[29] - [Kubernetes Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)
